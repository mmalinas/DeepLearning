{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breastcancer_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnnTwHW17dBLGdnHKWRDa3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmalinas/DeepLearning/blob/master/breastcancer_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gZ91WNN-CkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5402e90a-4ef7-45d3-b2ba-6b859754b528"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br50DWws8aBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset():\n",
        "    \n",
        "    lmd_tic = time.time()\n",
        "    \n",
        "    filename_prefix = '/content/drive/My Drive/breast-normalized-dataset_'\n",
        "\n",
        "    filename_suffixes = ['training_class0.h5', 'validation_class0.h5', 'test_class0.h5', \n",
        "                         'training_class1.h5', 'validation_class1.h5', 'test_class1.h5']\n",
        "\n",
        "    X_training_class0 = []\n",
        "    X_validation_class0 = []\n",
        "    X_test_class0 = []\n",
        "    X_training_class1 = []\n",
        "    X_validation_class1 = []\n",
        "    X_test_class1 = []\n",
        "\n",
        "    Y_training_class0 = []\n",
        "    Y_validation_class0 = []\n",
        "    Y_test_class0 = []\n",
        "    Y_training_class1 = []\n",
        "    Y_validation_class1 = []\n",
        "    Y_test_class1 = []\n",
        "\n",
        "\n",
        "    with h5py.File(filename_prefix+filename_suffixes[0], 'r') as f_training_class0:\n",
        "      X_training_class0.append(f_training_class0['training_class0'][:])\n",
        "      Y_training_class0.append(f_training_class0['labels'][:])\n",
        "    \n",
        "    with h5py.File(filename_prefix+filename_suffixes[1], 'r') as f_validation_class0:\n",
        "      X_validation_class0.append(f_validation_class0['validation_class0'][:])\n",
        "      Y_validation_class0.append(f_validation_class0['labels'][:])\n",
        "\n",
        "    with h5py.File(filename_prefix+filename_suffixes[2], 'r') as f_test_class0:\n",
        "      X_test_class0.append(f_test_class0['test_class0'][:])\n",
        "      Y_test_class0.append(f_test_class0['labels'][:])\n",
        "\n",
        "    with h5py.File(filename_prefix+filename_suffixes[3], 'r') as f_training_class1:\n",
        "      X_training_class1.append(f_training_class1['training_class1'][:])\n",
        "      Y_training_class1.append(f_training_class1['labels'][:])\n",
        "\n",
        "    with h5py.File(filename_prefix+filename_suffixes[4], 'r') as f_validation_class1:\n",
        "      X_validation_class1.append(f_validation_class1['validation_class1'][:])\n",
        "      Y_validation_class1.append(f_validation_class1['labels'][:])\n",
        "\n",
        "    with h5py.File(filename_prefix+filename_suffixes[5], 'r') as f_test_class1:\n",
        "      X_test_class1.append(f_test_class1['test_class1'][:])\n",
        "      Y_test_class1.append(f_test_class1['labels'][:])\n",
        "\n",
        "\n",
        "    X_training = [X_training_class0, X_training_class1]\n",
        "    X_validation = [X_validation_class0, X_validation_class1]\n",
        "    X_test = [X_test_class0, X_test_class1]\n",
        "\n",
        "    Y_training = [Y_training_class0, Y_training_class1]\n",
        "    Y_validation = [Y_validation_class0, Y_validation_class1]\n",
        "    Y_test = [Y_test_class0, Y_test_class1]\n",
        "\n",
        "    lmd_toc = time.time()\n",
        "    print('Time taken to load the data set is', ((lmd_toc-lmd_tic) * 1000), 'ms')\n",
        "    \n",
        "    return X_training, X_validation, X_test, Y_training, Y_validation, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMdrC_ba-Gko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MLP with manual validation set\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_training, Y_training, validation_data=(X_validation, Y_validation), epochs=150, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}